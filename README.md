# Machine-Learning-Training
Basic Machine Learning Algorithm  -
1. **Linear Regression**:
   - Linear regression is a simple and widely used algorithm for predicting a continuous value based on one or more input features.
   - It fits a straight line to the data points, minimizing the difference between the predicted and actual values.

2. **Logistic Regression**:
   - Logistic regression is used for binary classification tasks, where the output is a categorical variable with two possible outcomes.
   - It models the probability of the input belonging to a particular class using a logistic function.

3. **Decision Trees**:
   - Decision trees are versatile algorithms used for both classification and regression tasks.
   - They partition the feature space into regions and make predictions based on the majority class or average value of data points within each region.

4. **Random Forest**:
   - Random forest is an ensemble learning method that builds multiple decision trees and combines their predictions to improve accuracy and reduce overfitting.
   - It randomly selects subsets of features and data points for training each tree.

5. **Support Vector Machines (SVM)**:
   - SVM is a powerful algorithm for both classification and regression tasks.
   - It finds the hyperplane that best separates the data points of different classes while maximizing the margin between them.

6. **K-Nearest Neighbors (KNN)**:
   - KNN is a simple and intuitive algorithm used for classification and regression tasks.
   - It predicts the label or value of a data point based on the majority class or average value of its k nearest neighbors in the feature space.

7. **Gradient Boosting Machines (GBM)**:
   - GBM is an ensemble learning technique that builds a sequence of weak learners (typically decision trees) and combines their predictions to form a strong learner.
   - It minimizes the loss function by iteratively fitting new models to the residuals of the previous models.
